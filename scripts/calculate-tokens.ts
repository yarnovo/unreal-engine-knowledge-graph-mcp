import fs from "fs-extra";
import path from "path";
import { get_encoding } from "tiktoken";

// æ”¯æŒçš„ç¼–ç ç±»å‹
type SupportedEncoding = "o200k_base" | "cl100k_base" | "p50k_base" | "r50k_base";

interface TokenCalculationResult {
  filePath: string;
  fileName: string;
  fileSize: number;
  contentLength: number;
  tokenCount: number;
  encoding: string;
  avgCharsPerToken: number;
  estimatedApiCost?: number; // é¢„ä¼°APIæˆæœ¬ï¼ˆå¦‚æœæä¾›ä»·æ ¼ï¼‰
}

/**
 * è®¡ç®—æ–‡æœ¬å†…å®¹çš„ token æ•°é‡
 * @param content æ–‡æœ¬å†…å®¹
 * @param encoding ç¼–ç ç±»å‹ï¼Œé»˜è®¤ä¸º o200k_base (é€‚ç”¨äº GPT-4o å’Œ DeepSeek)
 * @returns token æ•°é‡
 */
export function calculateTokens(content: string, encoding: SupportedEncoding = "o200k_base"): number {
  try {
    const encoder = get_encoding(encoding);
    const tokens = encoder.encode(content);
    const tokenCount = tokens.length;
    encoder.free(); // é‡Šæ”¾ç¼–ç å™¨èµ„æº
    return tokenCount;
  } catch (error) {
    throw new Error(`Token è®¡ç®—å¤±è´¥: ${(error as Error).message}`);
  }
}

/**
 * è®¡ç®—æ–‡ä»¶çš„ token æ•°é‡å’Œç›¸å…³ç»Ÿè®¡ä¿¡æ¯
 * @param filePath æ–‡ä»¶è·¯å¾„
 * @param encoding ç¼–ç ç±»å‹
 * @returns è¯¦ç»†çš„è®¡ç®—ç»“æœ
 */
export async function calculateFileTokens(
  filePath: string, 
  encoding: SupportedEncoding = "o200k_base"
): Promise<TokenCalculationResult> {
  try {
    // æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if (!await fs.pathExists(filePath)) {
      throw new Error(`æ–‡ä»¶ä¸å­˜åœ¨: ${filePath}`);
    }

    // è·å–æ–‡ä»¶ä¿¡æ¯
    const fileStat = await fs.stat(filePath);
    const fileName = path.basename(filePath);
    
    // è¯»å–æ–‡ä»¶å†…å®¹
    const content = await fs.readFile(filePath, 'utf-8');
    
    // è®¡ç®— token æ•°é‡
    const tokenCount = calculateTokens(content, encoding);
    
    // è®¡ç®—å¹³å‡æ¯ä¸ª token çš„å­—ç¬¦æ•°
    const avgCharsPerToken = content.length > 0 ? content.length / tokenCount : 0;
    
    return {
      filePath,
      fileName,
      fileSize: fileStat.size,
      contentLength: content.length,
      tokenCount,
      encoding,
      avgCharsPerToken,
    };
  } catch (error) {
    throw new Error(`æ–‡ä»¶ token è®¡ç®—å¤±è´¥: ${(error as Error).message}`);
  }
}

/**
 * æ ¼å¼åŒ–è¾“å‡ºè®¡ç®—ç»“æœ
 * @param result è®¡ç®—ç»“æœ
 * @param verbose æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
 */
function formatOutput(result: TokenCalculationResult, verbose: boolean = false): void {
  console.log(`\nğŸ“Š Token è®¡ç®—ç»“æœ:`);
  console.log(`   ğŸ“ æ–‡ä»¶: ${result.fileName}`);
  console.log(`   ğŸ“ è·¯å¾„: ${result.filePath}`);
  
  if (verbose) {
    console.log(`   ğŸ“¦ æ–‡ä»¶å¤§å°: ${formatBytes(result.fileSize)}`);
    console.log(`   ğŸ“ å†…å®¹é•¿åº¦: ${result.contentLength.toLocaleString()} å­—ç¬¦`);
    console.log(`   ğŸ”¤ ç¼–ç ç±»å‹: ${result.encoding}`);
    console.log(`   ğŸ“ å­—ç¬¦/Tokenæ¯”: ${result.avgCharsPerToken.toFixed(2)}`);
  }
  
  console.log(`   ğŸ¯ Token æ•°é‡: ${result.tokenCount.toLocaleString()}`);
  
  // æä¾›ä¸€äº›æœ‰ç”¨çš„å‚è€ƒä¿¡æ¯
  if (verbose) {
    console.log(`\nğŸ’¡ å‚è€ƒä¿¡æ¯:`);
    
    // DeepSeek API é™åˆ¶å‚è€ƒ
    if (result.tokenCount > 65536) {
      console.log(`   âš ï¸  è¶…å‡º DeepSeek ä¸Šä¸‹æ–‡é™åˆ¶ (65,536 tokens)`);
      const chunksNeeded = Math.ceil(result.tokenCount / 60000);
      console.log(`   ğŸ”ª å»ºè®®åˆ‡ç‰‡æ•°é‡: ${chunksNeeded} ä¸ª (æ¯ç‰‡çº¦ 60k tokens)`);
    } else if (result.tokenCount > 32768) {
      console.log(`   âš ï¸  æ¥è¿‘ DeepSeek ä¸Šä¸‹æ–‡é™åˆ¶ï¼Œå»ºè®®è€ƒè™‘åˆ‡ç‰‡`);
    } else {
      console.log(`   âœ… åœ¨ DeepSeek ä¸Šä¸‹æ–‡é™åˆ¶å†…`);
    }
    
    // ä¼°ç®—å¤„ç†æ—¶é—´ï¼ˆåŸºäºç»éªŒï¼‰
    const estimatedSeconds = Math.ceil(result.tokenCount / 1000) * 2; // å¤§è‡´ä¼°ç®—
    console.log(`   â±ï¸  é¢„ä¼°å¤„ç†æ—¶é—´: ~${estimatedSeconds} ç§’`);
  }
}

/**
 * æ ¼å¼åŒ–å­—èŠ‚å¤§å°
 */
function formatBytes(bytes: number): string {
  if (bytes === 0) return '0 Bytes';
  const k = 1024;
  const sizes = ['Bytes', 'KB', 'MB', 'GB'];
  const i = Math.floor(Math.log(bytes) / Math.log(k));
  return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i];
}

/**
 * æ˜¾ç¤ºä½¿ç”¨å¸®åŠ©
 */
function showHelp(): void {
  console.log(`
ğŸ”¢ Token è®¡ç®—å·¥å…·

ç”¨æ³•:
  node dist/scripts/calculate-tokens.js <æ–‡ä»¶è·¯å¾„> [é€‰é¡¹]

å‚æ•°:
  <æ–‡ä»¶è·¯å¾„>          è¦è®¡ç®— token çš„æ–‡ä»¶è·¯å¾„

é€‰é¡¹:
  -e, --encoding      ç¼–ç ç±»å‹ (é»˜è®¤: o200k_base)
                      æ”¯æŒ: o200k_base, cl100k_base, p50k_base, r50k_base
  -v, --verbose       æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
  -h, --help          æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯

ç¼–ç è¯´æ˜:
  o200k_base         GPT-4o, DeepSeek (æ¨è)
  cl100k_base        GPT-4, GPT-3.5-turbo
  p50k_base          GPT-3, text-davinci-003
  r50k_base          GPT-3, text-davinci-002

ç¤ºä¾‹:
  node dist/scripts/calculate-tokens.js ./sources/docs/my-doc.md
  node dist/scripts/calculate-tokens.js ./sources/docs/my-doc.md -v
  node dist/scripts/calculate-tokens.js ./sources/docs/my-doc.md -e cl100k_base
  npm run build && node dist/scripts/calculate-tokens.js ./sources/docs/my-doc.md -v
`);
}

/**
 * è§£æå‘½ä»¤è¡Œå‚æ•°
 */
function parseArgs(args: string[]): {
  filePath?: string;
  encoding: SupportedEncoding;
  verbose: boolean;
  help: boolean;
} {
  const result = {
    filePath: undefined as string | undefined,
    encoding: "o200k_base" as SupportedEncoding,
    verbose: false,
    help: false
  };

  for (let i = 0; i < args.length; i++) {
    const arg = args[i];
    
    if (arg === '-h' || arg === '--help') {
      result.help = true;
    } else if (arg === '-v' || arg === '--verbose') {
      result.verbose = true;
    } else if (arg === '-e' || arg === '--encoding') {
      const nextArg = args[i + 1];
      if (nextArg && ['o200k_base', 'cl100k_base', 'p50k_base', 'r50k_base'].includes(nextArg)) {
        result.encoding = nextArg as SupportedEncoding;
        i++; // è·³è¿‡ä¸‹ä¸€ä¸ªå‚æ•°
      } else {
        throw new Error(`æ— æ•ˆçš„ç¼–ç ç±»å‹: ${nextArg}`);
      }
    } else if (!arg.startsWith('-')) {
      // å¦‚æœä¸æ˜¯é€‰é¡¹å‚æ•°ï¼Œåˆ™è®¤ä¸ºæ˜¯æ–‡ä»¶è·¯å¾„
      if (!result.filePath) {
        result.filePath = arg;
      }
    }
  }

  return result;
}

/**
 * ä¸»å‡½æ•° - å‘½ä»¤è¡Œå…¥å£
 */
async function main(): Promise<void> {
  try {
    const args = process.argv.slice(2); // å»æ‰ node å’Œè„šæœ¬åç§°
    
    if (args.length === 0) {
      showHelp();
      return;
    }

    const options = parseArgs(args);
    
    if (options.help) {
      showHelp();
      return;
    }

    if (!options.filePath) {
      console.error('âŒ é”™è¯¯: è¯·æä¾›æ–‡ä»¶è·¯å¾„');
      console.log('ä½¿ç”¨ -h æˆ– --help æŸ¥çœ‹ä½¿ç”¨è¯´æ˜');
      process.exit(1);
    }

    console.log('ğŸ”¢ å¼€å§‹è®¡ç®— Token æ•°é‡...');
    
    const result = await calculateFileTokens(options.filePath, options.encoding);
    formatOutput(result, options.verbose);

  } catch (error) {
    console.error('âŒ è®¡ç®—å¤±è´¥:', (error as Error).message);
    process.exit(1);
  }
}

// å¦‚æœæ˜¯ç›´æ¥è¿è¡Œæ­¤è„šæœ¬ï¼Œåˆ™æ‰§è¡Œä¸»å‡½æ•°
if (process.argv[1] && process.argv[1].includes('calculate-tokens')) {
  main();
} 